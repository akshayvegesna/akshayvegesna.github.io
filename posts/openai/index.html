<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>OpenAI&#39;s Dominance in the Intelligence API Market | Akshay Vegesna</title>
<meta name="keywords" content="">
<meta name="description" content="When asked why they don&rsquo;t train their own models, new LLM product companies might respond with a smile and a well-practiced &lsquo;GPT-4 works pretty well for our use-case.&rsquo; Beneath this response, there are two underlying risks that these companies must confront
technical execution risk to train one&rsquo;s own LLMs, and product risk in order to make something people want. The technical risk shouldn&rsquo;t be understated. Many ML product companies are made by people in different industries: think lawyers, marketers, etc.">
<meta name="author" content="">
<link rel="canonical" href="http://akshayvegesna.github.io/posts/openai/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css" integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://akshayvegesna.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://akshayvegesna.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://akshayvegesna.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://akshayvegesna.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="http://akshayvegesna.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="OpenAI&#39;s Dominance in the Intelligence API Market" />
<meta property="og:description" content="When asked why they don&rsquo;t train their own models, new LLM product companies might respond with a smile and a well-practiced &lsquo;GPT-4 works pretty well for our use-case.&rsquo; Beneath this response, there are two underlying risks that these companies must confront
technical execution risk to train one&rsquo;s own LLMs, and product risk in order to make something people want. The technical risk shouldn&rsquo;t be understated. Many ML product companies are made by people in different industries: think lawyers, marketers, etc." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://akshayvegesna.github.io/posts/openai/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-07T13:04:28-07:00" />
<meta property="article:modified_time" content="2023-05-07T13:04:28-07:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="OpenAI&#39;s Dominance in the Intelligence API Market"/>
<meta name="twitter:description" content="When asked why they don&rsquo;t train their own models, new LLM product companies might respond with a smile and a well-practiced &lsquo;GPT-4 works pretty well for our use-case.&rsquo; Beneath this response, there are two underlying risks that these companies must confront
technical execution risk to train one&rsquo;s own LLMs, and product risk in order to make something people want. The technical risk shouldn&rsquo;t be understated. Many ML product companies are made by people in different industries: think lawyers, marketers, etc."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://akshayvegesna.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "OpenAI's Dominance in the Intelligence API Market",
      "item": "http://akshayvegesna.github.io/posts/openai/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "OpenAI's Dominance in the Intelligence API Market",
  "name": "OpenAI\u0027s Dominance in the Intelligence API Market",
  "description": "When asked why they don\u0026rsquo;t train their own models, new LLM product companies might respond with a smile and a well-practiced \u0026lsquo;GPT-4 works pretty well for our use-case.\u0026rsquo; Beneath this response, there are two underlying risks that these companies must confront\ntechnical execution risk to train one\u0026rsquo;s own LLMs, and product risk in order to make something people want. The technical risk shouldn\u0026rsquo;t be understated. Many ML product companies are made by people in different industries: think lawyers, marketers, etc.",
  "keywords": [
    
  ],
  "articleBody": "When asked why they don’t train their own models, new LLM product companies might respond with a smile and a well-practiced ‘GPT-4 works pretty well for our use-case.’ Beneath this response, there are two underlying risks that these companies must confront\ntechnical execution risk to train one’s own LLMs, and product risk in order to make something people want. The technical risk shouldn’t be understated. Many ML product companies are made by people in different industries: think lawyers, marketers, etc. A company must choose between a few different options when developing ML products:\nTraining one’s own models is a tall task technically and requires significant up-front capital even if you know what you’re doing. In particular, you must get many GPUs from your cloud provider of choice, train a model on those GPUs (requires expertise), and serve the models yourself on a VM as the endpoint for your application. Outsource this to a training manager (mosaicML), and then serve the models in the way that you prefer. Use an OpenAI API call. In this case, you will have to write careful prompts and tests in order to move forward. Note that it is cheap enough for most applications: $0.03 / 1K tokens for GPT-4. $0.002 / 1K tokens for GPT-3.5. If you thought this technical risk was reason enough to use openAI’s models, here enters our good friend: product risk. Just like Mike Tyson said “Everyone has a plan: until they get punched in the face.”, one can make a similar product parallel: “Everyone has a plan: until people use their product.” Your usage vision and people’s preferences often diverge and so you will have to adapt, often in extreme ways. AI companies need to make sure that the models that they are training are exactly useful for what the market demands. And so, training your models before you find some product market fit (or some equivalent market de-risking) is often a bad idea.\nHere’s an adjacent story: OpenAI has all but cornered the market demand for an intelligence platform in its API offering. And probably like any other company that is crossing the chasm, the goal is to create extreme demand to take over the market.\nAt this point, I want to introduce an idea from tech economics: smart companies try to make their complements a commodity. There are many reasons for this: (a) competition in the commoditized markets means that no monopolist can emerge, (b) the low price for commodities means that there is a large consumer surplus that they can eat up by their monopoly. An example of this is Microsoft pushing PC hardware to become a commodity. Since the Microsoft operating system was a complement to the PC hardware, they were able to demand higher prices for their operating system in their monopoly position, increasing revenue.\nThe natural complement to an intelligence API is the product that users use. So for example, a software application that allows users to perform chat operations with a document. In this case, the customers will pay for this product offering - and the revenue will be split between the production company and OpenAI’s API cost. If the barrier to entry is low and there are other companies that can do this easily, then you risk having to compete on price. So a lesson for vertical startups is to make your wrapper for OpenAI as “fat” as possible or risk becoming an undifferentiated commodity. Also, find a way to avoid this hyper-competition.\nI’d also argue that there are some leading indicators of easing barriers to entry in this space:\nCompanies making AI agents are aimed at developers to prototype quickly. Langchain, Fixie. OpenAI itself is trying to make it easy for startups in this space. Fund, Grant. These with lower the entry barriers for the new startups entering the space, leading to increased competition.\nAnd while Sam Altman can truthfully say that there’s never been a better time to start an AI startup, it’s important to recognize that startups must navigate the risks and challenges that come with relying on OpenAI, or else risk having the majority of consumer surpluses go to OpenAI.\n",
  "wordCount" : "692",
  "inLanguage": "en",
  "datePublished": "2023-05-07T13:04:28-07:00",
  "dateModified": "2023-05-07T13:04:28-07:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://akshayvegesna.github.io/posts/openai/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Akshay Vegesna",
    "logo": {
      "@type": "ImageObject",
      "url": "http://akshayvegesna.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://akshayvegesna.github.io/" accesskey="h" title="Akshay Vegesna (Alt + H)">Akshay Vegesna</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      OpenAI&#39;s Dominance in the Intelligence API Market
    </h1>
    <div class="post-meta"><span title='2023-05-07 13:04:28 -0700 PDT'>May 7, 2023</span>

</div>
  </header> 
  <div class="post-content"><p>When asked why they don&rsquo;t train their own models, new LLM product companies might respond with a smile and a well-practiced &lsquo;GPT-4 works pretty well for our use-case.&rsquo; Beneath this response, there are two underlying risks that these companies must confront</p>
<ol>
<li>technical execution risk to train one&rsquo;s own LLMs, and</li>
<li>product risk in order to make something people want.</li>
</ol>
<p>The technical risk shouldn&rsquo;t be understated. Many ML product companies are made by people in different industries: think lawyers, marketers, etc. A company must choose between a few different options when developing ML products:</p>
<ul>
<li>Training one&rsquo;s own models is a tall task technically and requires significant up-front capital even if you know what you&rsquo;re doing. In particular, you must get many GPUs from your cloud provider of choice, train a model on those GPUs (requires expertise), and serve the models yourself on a VM as the endpoint for your application.</li>
<li>Outsource this to a training manager (mosaicML), and then serve the models in the way that you prefer.</li>
<li>Use an OpenAI API call. In this case, you will have to write careful prompts and tests in order to move forward. Note that it is cheap enough for most applications: $0.03 / 1K tokens for GPT-4. $0.002 / 1K tokens for GPT-3.5.</li>
</ul>
<p>If you thought this technical risk was reason enough to use openAI&rsquo;s models, here enters our good friend: product risk. Just like Mike Tyson said &ldquo;Everyone has a plan: until they get punched in the face.&rdquo;, one can make a similar product parallel: &ldquo;Everyone has a plan: until people use their product.&rdquo; Your usage vision and people&rsquo;s preferences often diverge and so you will have to adapt, often in extreme ways. AI companies need to make sure that the models that they are training are exactly useful for what the market demands. And so, training your models before you find some product market fit (or some equivalent market de-risking) is often a bad idea.</p>
<p>Here&rsquo;s an adjacent story: OpenAI has all but cornered the market demand for an intelligence platform in its API offering. And probably like any other company that is crossing the chasm, the goal is to create extreme demand to take over the market.</p>
<p>At this point, I want to introduce an idea from tech economics: smart companies try to make their complements a <a href="https://gwern.net/complement">commodity</a>. There are many reasons for this: (a) competition in the commoditized markets means that no monopolist can emerge, (b) the low price for commodities means that there is a large consumer surplus that they can eat up by their monopoly. An example of this is Microsoft pushing PC hardware to become a commodity. Since the Microsoft operating system was a complement to the PC hardware, they were able to demand higher prices for their operating system in their monopoly position, increasing revenue.</p>
<p>The natural complement to an intelligence API is the product that users use. So for example, a software application that allows users to perform chat operations with a document. In this case, the customers will pay for this product offering - and the revenue will be split between the production company and OpenAI&rsquo;s API cost. If the barrier to entry is low and there are other companies that can do this easily, then you risk having to compete on price. So a lesson for vertical startups is to make your wrapper for OpenAI as &ldquo;fat&rdquo; as possible or risk becoming an undifferentiated commodity. Also, find a way to avoid this hyper-competition.</p>
<p>I&rsquo;d also argue that there are some leading indicators of easing barriers to entry in this space:</p>
<ul>
<li>Companies making AI agents are aimed at developers to prototype quickly. <a href="https://blog.langchain.dev/">Langchain</a>, <a href="https://www.fixie.ai/">Fixie</a>.</li>
<li>OpenAI itself is trying to make it easy for startups in this space. <a href="https://openai.fund/">Fund</a>, <a href="https://docs.google.com/forms/d/e/1FAIpQLSdKdoWu8hmDfvhuBOzp4hOnkvZfvX5qPNlrHtvCvdIM3bjJ8w/viewform">Grant</a>.</li>
</ul>
<p>These with lower the entry barriers for the new startups entering the space, leading to increased competition.</p>
<p>And while Sam Altman can truthfully say that there&rsquo;s never been a better time to start an AI startup, it&rsquo;s important to recognize that startups must navigate the risks and challenges that come with relying on OpenAI, or else risk having the majority of consumer surpluses go to OpenAI.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
