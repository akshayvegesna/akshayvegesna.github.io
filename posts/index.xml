<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Akshay Vegesna</title>
    <link>http://akshayvegesna.github.io/posts/</link>
    <description>Recent content in Posts on Akshay Vegesna</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Apr 2024 09:51:16 -0700</lastBuildDate><atom:link href="http://akshayvegesna.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>explaining experiment results</title>
      <link>http://akshayvegesna.github.io/posts/explain/</link>
      <pubDate>Wed, 03 Apr 2024 09:51:16 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/explain/</guid>
      <description>An important job of a scientist is to explain results of experiments. Once you have an explanation, you can design further experiments. Without good explanations, you will design bad experiments and fail.
Using Bayes rule, the formula for an explanation given results of experiments is:
P(explanation | experiment_results) = P(experiment_results | explanation) * P(explanation) / P(experiment_results) = P (experiment_results | explanation) * P(explanation) / \sum_{explanation_i}^{all_explanations} P(experiment_result | explanation_i) P(explanation_i) Ok so what does it mean?</description>
    </item>
    
    <item>
      <title>Obvious things in hindsight</title>
      <link>http://akshayvegesna.github.io/posts/obvious/</link>
      <pubDate>Wed, 10 Jan 2024 10:11:17 -0800</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/obvious/</guid>
      <description>Simplifying complicated concepts makes them easier to understand and extend. Extending ideas is risky and valuable. You leave a lot on the table when you don&amp;rsquo;t pay attention. Understand when to be arrogant and when to be humble. Be capable of arrogance. People remember kindness. Your (perceived) energy is what people pick up on in social situations. Determination matters. The goal of a workout routine is to minimize the mental headspace it takes.</description>
    </item>
    
    <item>
      <title>how to work as hard as you can</title>
      <link>http://akshayvegesna.github.io/posts/work/</link>
      <pubDate>Fri, 29 Dec 2023 10:48:24 -0800</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/work/</guid>
      <description>“If everything seems under control, you&amp;rsquo;re just not going fast enough.” - Mario Andretti
I recently started a startup. The goal most days is to get as much done as possible. Here are some tactical tips for humans trying to work 14 hour days, 6 days a week.
have a routine Routines make superhuman feats repeatable. &amp;lsquo;I did it yesterday&amp;rsquo; is a great motivation tool.
I&amp;rsquo;d recommend to make some of these invariants.</description>
    </item>
    
    <item>
      <title>Greatness</title>
      <link>http://akshayvegesna.github.io/posts/great/</link>
      <pubDate>Thu, 28 Dec 2023 13:08:36 -0800</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/great/</guid>
      <description>&amp;ldquo;Greatness is never simply a multiplier of the ordinary; it has other qualities entirely.&amp;rdquo;
andy grove Andy grove was an extremely tough pragmatist. He worked incredibly hard, asked cutting questions, while at the same time treating people with respect.
max levchin He is extremely intelligent and hard working. He was obviously a better programmer than anyone else when he started paypal. Lacked strong principles and some business/product sense at that time.</description>
    </item>
    
    <item>
      <title>A Correct Prediction</title>
      <link>http://akshayvegesna.github.io/posts/pred/</link>
      <pubDate>Fri, 13 Oct 2023 09:29:58 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/pred/</guid>
      <description>I am obsessed with the predictions that GPT-4 or something like it was coming in the early 2020s. Ray Kurzweil was able to predict this in 2005.
The simple reasoning is this. The model architecture for a computer, like the human brain, is not hard to find. Moore&amp;rsquo;s law will not bend, so we will have compute at the level of the human brain by 2020-2025. So we can make a computer like a human brain around this time.</description>
    </item>
    
    <item>
      <title>Notes on How We Know - Harry Binswanger</title>
      <link>http://akshayvegesna.github.io/posts/know/</link>
      <pubDate>Sat, 16 Sep 2023 00:14:41 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/know/</guid>
      <description>These are various notes on How We Know - Harry Binswanger. I focus on Chapters 7 and 10 since they are the most practical.
Chapter 7 - Logic: Practice
Logic covers concept formation, propositional judgment, and inference Every word denotes a concept. The definition is a label on the concept. Sensations don&amp;rsquo;t have definitions. Those things are. Foils and examples can explain it. Ex: existence, consciousness Rules of proper definition definition consists of genus and the differentia.</description>
    </item>
    
    <item>
      <title>companies worth creating</title>
      <link>http://akshayvegesna.github.io/posts/create/</link>
      <pubDate>Tue, 08 Aug 2023 19:56:02 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/create/</guid>
      <description>George Hotz had a great talk at Comma Con in which he said:
Build companies that will change the future, not the distribution of wealth in the future.
That&amp;rsquo;s a nice line. Some products are in crowded spaces that were just a matter of time - the nth frontend authentication product might be one. These will materially change the distribution of wealth in the future but not the future itself.</description>
    </item>
    
    <item>
      <title>blinders off</title>
      <link>http://akshayvegesna.github.io/posts/blinders/</link>
      <pubDate>Sat, 29 Jul 2023 23:12:28 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/blinders/</guid>
      <description>Dalton Caldwell and Paul Graham have pointed to this idea in startups of &amp;ldquo;having blinders on&amp;rdquo; during idea generation. They have found that founders cannot see what is right in front of their eyes due to blinders - obstructions that block them from seeing the truth. This phenomenon usually occurs when deciding what to work on while pivoting and developing an initial product.
The blinders arise for different reasons. Some examples:</description>
    </item>
    
    <item>
      <title>user experience and AI capability - value isn&#39;t all delight</title>
      <link>http://akshayvegesna.github.io/posts/cap/</link>
      <pubDate>Wed, 12 Jul 2023 17:32:48 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/cap/</guid>
      <description>tldr; for many old UX&amp;rsquo;s, there exists an AI capability threshold that amplifies the value prop
Everyone has had a good experience with a product recently. When your AirPods arrive in the mail, you flick the case open and place them tentatively in your ears. The noise-canceling headphones stream Anderson Paak in his distinctive soulful sound. A good product makes an indelible impression on its user - initially in terms of delight but also value over time.</description>
    </item>
    
    <item>
      <title>Copilot</title>
      <link>http://akshayvegesna.github.io/posts/copilot/</link>
      <pubDate>Fri, 07 Jul 2023 22:03:31 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/copilot/</guid>
      <description>Here are rough notes (to self) on the copilot story. Source
knew that they wanted to build something using GPT-3 started prototyping: demo&amp;rsquo;s were fabulous demo being good is not a sufficient condition models were not good enough for chat interface - 25% answer that i love, 75% it was garbage code synthesis - synthesizing large function calls - not that satisfying small scale autocomplete with the large models -intellisense dropdown UI UI was not the right thing User would get multiple options for the function body - read and pick the right one use the human feedback to improve the model reasons this was bad hit a key to request it wait for it to come back read three functions and click the right one - too much cognitive effort result was that none of them were good or you didn&amp;rsquo;t know lots of effort on the user but not a lot coming out of it Alex said to use the cursor position in the AST to figure out where you are in the code if you are at the beginning, complete the whole block if you are in the middle, just complete one line automatically generated with no user interaction model was small enough to be low-latency but big enough to be accurate only once all of these pieces were in place did the median new user loved copilot other dead-ends too along the way.</description>
    </item>
    
    <item>
      <title>Succession</title>
      <link>http://akshayvegesna.github.io/posts/succession/</link>
      <pubDate>Fri, 30 Jun 2023 02:00:50 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/succession/</guid>
      <description>Spoiler alert: tons of spoilers for the TV show succession
I started and stopped watching succession about three times before I got into it. The reason was simple: all of the characters were unlikeable.
Then I got into it. And the reason why succession is good is because you can see competition for leadership by children who do not deserve it. And that&amp;rsquo;s relatable.
The following sequence occurs in the final episode</description>
    </item>
    
    <item>
      <title>Unconvincing</title>
      <link>http://akshayvegesna.github.io/posts/unconv/</link>
      <pubDate>Thu, 22 Jun 2023 11:47:38 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/unconv/</guid>
      <description>There&amp;rsquo;s something revolting about unconvincing ambitious people - those that claim there&amp;rsquo;s a billion dollar opportunity somewhere but with transparent naivete and thoughtlessness.</description>
    </item>
    
    <item>
      <title>Singularity</title>
      <link>http://akshayvegesna.github.io/posts/singular/</link>
      <pubDate>Sun, 18 Jun 2023 11:11:27 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/singular/</guid>
      <description>Someone once asked Gertrude Stein if she was a lesbian. Stein answered no, I just like Alice.
Looking for Alice is one of the most striking pieces I&amp;rsquo;ve read in recent memory. It gets at something that is hard to articulate - some people are distinctive in ways you can&amp;rsquo;t describe. There&amp;rsquo;s not a single theme that binds them, so it&amp;rsquo;s hard to talk about their qualities directly. The ones that I have met are aggressive, kind, and thoughtful.</description>
    </item>
    
    <item>
      <title>Laws of Preferences</title>
      <link>http://akshayvegesna.github.io/posts/pref/</link>
      <pubDate>Mon, 12 Jun 2023 20:53:26 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/pref/</guid>
      <description>Creating general laws in the real world is hard. Talk to an median investor, and you&amp;rsquo;ll hear confident advice about some startup subproblems. And the advice is regularly valuable. But occasionally, you&amp;rsquo;ll listen to a heuristic that is not well qualified or appropriately followed up with the indispensable, &amp;ldquo;but this is just a data point.&amp;rdquo; And you&amp;rsquo;ll ask yourself whether you should change course based on the advice.
The mechanism by which VCs or successful entrepreneurs give confident advice is well understood - they are in positions of power and wealth, and tons of young people look to them for advice.</description>
    </item>
    
    <item>
      <title>Compete</title>
      <link>http://akshayvegesna.github.io/posts/impl/compete/</link>
      <pubDate>Sat, 20 May 2023 21:51:53 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/impl/compete/</guid>
      <description>&amp;ldquo;I&amp;rsquo;d rather wrestle grizzlies than compete with Mrs. B.&amp;rdquo; - Warren Buffett
Some people are so good that you know they will do something great. Here we discuss the components of this in a famously good founder - Rose Blumkin. We&amp;rsquo;ll go through some of her exemplary qualities and go through some evidence. Much of this is take taken from the excellent Founder&amp;rsquo;s podcast on the subject.
Intrinsic drive + determination</description>
    </item>
    
    <item>
      <title>OpenAI&#39;s Dominance in the Intelligence API Market</title>
      <link>http://akshayvegesna.github.io/posts/openai/</link>
      <pubDate>Sun, 07 May 2023 13:04:28 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/openai/</guid>
      <description>When asked why they don&amp;rsquo;t train their own models, new LLM product companies might respond with a smile and a well-practiced &amp;lsquo;GPT-4 works pretty well for our use-case.&amp;rsquo; Beneath this response, there are two underlying risks that these companies must confront
technical execution risk to train one&amp;rsquo;s own LLMs, and product risk in order to make something people want. The technical risk shouldn&amp;rsquo;t be understated. Many ML product companies are made by people in different industries: think lawyers, marketers, etc.</description>
    </item>
    
    <item>
      <title>Autonomous Ride-sharing Markets</title>
      <link>http://akshayvegesna.github.io/posts/ars/</link>
      <pubDate>Sun, 30 Apr 2023 22:38:37 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/ars/</guid>
      <description>Billions of dollars have been spent on autonomous vehicles in the last decade but we have only recently seen the customer value on the other end. You can now hail Waymo and Cruise as a ride-sharing service in San Francisco. Technologists look at this and see a grand achievement. But business people sneer at the black box of autonomous vehicles sucking in tens of billions of dollars with so little to show in return.</description>
    </item>
    
    <item>
      <title>Motivation</title>
      <link>http://akshayvegesna.github.io/posts/impl/mot/</link>
      <pubDate>Fri, 31 Mar 2023 11:08:11 -0700</pubDate>
      
      <guid>http://akshayvegesna.github.io/posts/impl/mot/</guid>
      <description>As a creator, the desire to execute is one of the most important things to cultivate for one&amp;rsquo;s self. You can have months pass when you&amp;rsquo;re in an execution state, you feel indefatigable, things get done week after week, culminating in an impressive work product. This is why you work.
But then there are other times when you feel blocked. You wake up in the morning, make no real progress, and go to bed.</description>
    </item>
    
  </channel>
</rss>
